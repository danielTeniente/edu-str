{
    "app": {
        "title": "Machine Learning Libre",
        "welcome": "¬°Bienvenido! üéì",
        "description": "Esta aplicaci√≥n proporciona visualizaciones interactivas para comprender conceptos de machine learning. Utiliza el men√∫ lateral para navegar por las secciones.",
        "available_sections": "Secciones disponibles:",
        "navigation": "Navegaci√≥n",
        "language": "Idioma"
    },
    "perceptron": {
        "title": "El perceptr√≥n",
        "description": "El perceptr√≥n es un concepto clave, pues las redes neuronales modernas utilizan este elemento como bloque de construcci√≥n. \n\n Se trata de una neurona capaz de hacer una clasificaci√≥n binaria en base a una regresi√≥n lineal y una funci√≥n de activaci√≥n.",
        "info_linear_regression": "Es importante que ya conozcas la regresi√≥n lineal, puedes verla en este mismo proyecto.",
        "equations_title": "Ecuaci√≥n del perceptr√≥n",
        "perceptron_eq_desc_p1": "El perceptr√≥n clasifica un punto (x‚ÇÅ, x‚ÇÇ) bas√°ndose en esta ecuaci√≥n:",
        "perceptron_eq_desc_p2": "Lo entenderemos todo en un segundo, pero primero revisemos esta ecuaci√≥n:",
        "perceptron_eq_desc_p3": "Esta ecuaci√≥n representa la frontera de decisi√≥n. Es decir, divide los datos en dos conjuntos. Y si movemos algunas variables, podemos obtener la ecuaci√≥n de la recta:",
        "perceptron_eq_desc_p4": "Y recuerda la ecuaci√≥n de la recta.",
        "perceptron_eq_desc_p5": "* La pendiente **m** es **-w‚ÇÅ/w‚ÇÇ**\n\n* El corte en el eje vertical **b** es **-b/w‚ÇÇ**",
        "perceptron_ex":"Puedes jugar con los valores del perceptr√≥n para ver c√≥mo cambia la clasificaci√≥n",
        "activation_title": "Funci√≥n de activaci√≥n",
        "activation_text": "Ahora podemos continuar a la funci√≥n de activaci√≥n **f(z)**. Esta funci√≥n determina a qu√© clase pertenece cada punto.\n\n Veamos su definici√≥n m√°s simple:",
        "activation_text_p2": "Si el valor de **z** es mayor o igual a cero, la funci√≥n devuelve 1. Si el valor de **z** es menor que cero, la funci√≥n devuelve -1. Recordemos la ecuaci√≥n del perceptr√≥n:",
        "activation_text_p3": "Y esto ya lo pudiste ver en el ejemplo anterior. Todo lo que est√° sobre la frontera de decisi√≥n es de una clase, y todo lo que est√° debajo es de la otra.",
        "exercise_title": "Ejercicios",
        "exercise1_title": "Ejercicio 1",
        "exercise_desc": "Intenta clasificar estos puntos ajustando los pesos y el bias. El objetivo es encontrar una l√≠nea que separe los puntos azules de los rojos.",
        "weight1": "Peso w1",
        "weight2": "Peso w2",
        "bias": "Bias (b)",
        "class1": "Clase 1 (y=1)",
        "class_neg1": "Clase -1 (y=-1)",
        "decision_boundary": "Frontera de decisi√≥n",
        "graph_title": "Clasificaci√≥n del Perceptr√≥n y Frontera de Decisi√≥n",
        "exercise_plot_title": "Clasificaci√≥n Pr√°ctica",
        "exercise_success": "¬°Felicitaciones! Has clasificado correctamente todos los puntos.",
        "exercise_continue": "A veces no todos los puntos pueden ser separados, pero la idea es clasificar correctamente tantos como sea posible.",
        "correct_class1": "Puntos correctamente \n\nclasificados (y=1)",
        "correct_class_neg1": "Puntos correctamente \n\nclasificados (y=-1)",
        "misclassified": "Puntos mal clasificados",
        "exercise2_title": "Ejercicio 2",
        "exercise2_desc": "Ahora vamos a modelar una funci√≥n l√≥gica. Intenta modelar estas funciones:",
        "exercise2_or": "OR: cuando cualquiera de las entradas es 1, la salida es 1",
        "exercise2_and": "AND: cuando todas las entradas son 1, la salida es 1",
        "exercise2_nand": "NAND: cuando todas las entradas son 1, la salida es -1",
        "exercise2_nor": "NOR: cuando todas las entradas son -1, la salida es 1",
        "exercise2_xor": "XOR: cuando las entradas son diferentes, la salida es 1",
        "exercise2_nor_warning": "¬°Ojo! El perceptr√≥n no puede modelar la funci√≥n NOR, ya que no es linealmente separable.",
        "exercise2_result": "Resultado: est√°s modelando una funci√≥n:",
        "limitations_title": "Limitaciones del Perceptr√≥n",
        "limitations_desc": "El perceptr√≥n solo puede aprender patrones Lineales, no puede aprender algo como esto:",
        "limitations_plot_title": "Datos No Linealmente Separables",
        "limitations_text": "En este ejemplo, tenemos dos clases de puntos que forman un patr√≥n circular. Ninguna l√≠nea recta puede separar estos puntos correctamente. Esta es la gran limitaci√≥n del perceptr√≥n que lo mantuvo en el limbo de la historia... hasta la llegada del perceptr√≥n multicapa y el backpropagation.",
        "division_by_zero": "Cuando w‚ÇÇ = 0, la frontera de decisi√≥n se convierte en una l√≠nea vertical en x‚ÇÅ = -b/w‚ÇÅ. La ecuaci√≥n de la l√≠nea no puede escribirse en forma pendiente-ordenada al origen en este caso."
    },
    "line_basic": {
        "title": "Recuerda la recta b√°sica",
        "description_p1": "Recordemos que en un plano cartesiano, podemos graficar una recta siguiendo la siguiente ecuaci√≥n:",
        "description_p2": "La variable **y** se representa en el eje vertical, mientras que la variable **x**, en el eje horizontal. La pendiente **m** determina la inclinaci√≥n de la recta, mientras que **b** es el punto donde la recta corta el eje **y**.",
        "exercise_desc":"Puedes jugar con los deslizadores para ver c√≥mo afectan a la recta el valor de la pendiente **m** y el corte **b**",
        "slope": "Pendiente (m)",
        "intercept": "Ordenada al origen (b)",
        "plot_title": "Ecuaci√≥n de la Recta: y = mx + b"
    },
    "linear_regression": {
        "title": "Regresi√≥n Lineal",
        "description_p1": "La regresi√≥n lineal es un algoritmo f√°cil de entender. Consideramos que la relaci√≥n entre dos variables puede verse como una l√≠nea recta.",
        "ex_title": "Ejemplo de un escenario real",
        "ex_desc_p1": "Imagina que queremos predecir la altura de una persona (joven) en funci√≥n de su edad. Podemos usar la regresi√≥n lineal para encontrar una recta que se ajuste a los datos.",
        "ex_desc_p2": "En este caso, la variable independiente **x** es la edad y la variable dependiente **y** es la altura.",
        "ex_interactive_desc": "Puedes jugar con los deslizadores para encontrar una recta que pueda modelar los datos.",
        "ex_plot_title": "Ejemplo de Regresi√≥n Lineal usando la altura de una persona",
        "ex_plot_x_label": "Edad (a√±os)",
        "ex_plot_y_label": "Altura (cm)",
        "ex_rmse": "Ra√≠z del Error Cuadr√°tico Medio (RMSE):",
        "ex_hint": "Pista: Intenta minimizar el valor del Error (RMSE)",
        "error_eq_title": "¬øC√≥mo medimos el error?",
        "error_eq_desc_p1": "Para saber si nuestro modelo es bueno, medimos la distancia entre los valores predichos y los valores reales.",
        "error_eq_desc_p2": "Y eso representa el Error Cuadr√°tico Medio (MSE):",
        "error_eq_params": "‚Ä¢ Donde **n** es el n√∫mero de puntos\n\n‚Ä¢ **y·µ¢** es el valor real de para el punto i\n\n‚Ä¢ **≈∑·µ¢** es el valor predicho para el punto i\n\n‚Ä¢ Y cuanto menor sea el MSE, mejor ser√° el ajuste.",
        "error_eq_desc_p3": "Nota que medimos la diferencia entre el valor real **y·µ¢** y el valor predicho **≈∑·µ¢** para cada punto **i**.",
        "error_eq_desc_p4": "Elevar la diferencia al cuadrado tiene dos consecuencias:",
        "error_eq_desc_p5": "1. Los errores grandes son m√°s importantes que los errores peque√±os\n\n2. La diferencia siempre es positiva, as√≠ que no importa si el modelo predice m√°s o menos que el valor real, el error ser√° positivo.",
        "error_eq_desc_p6": "A este valor se le puede aplicar la ra√≠z cuadrada para obtener el error en las mismas unidades que los valores reales.",
        "slope": "Pendiente (m)",
        "intercept": "Ordenada al origen (b)",
        "best_fit": "L√≠nea de Mejor Ajuste",
        "data_points": "Puntos de Datos",
        "error_lines": "L√≠neas de Error",
        "show_errors": "Mostrar l√≠neas de error",
        "plot_title": "L√≠nea de Regresi√≥n Lineal y Puntos de Datos",
        "explanation_title": "Entendiendo la Regresi√≥n Lineal",
        "explanation_text": "‚Ä¢ Asumimos que existe una relaci√≥n lineal entre dos variables.\n\n‚Ä¢ La manera m√°s f√°cil de percibir una relaci√≥n lineal es graficar los valores en un plano cartesiano.\n\n‚Ä¢ Ning√∫n modelo es perfecto, siempre existir√° algo de error porque el mundo real no tiene l√≠neas rectas.\n\n‚Ä¢ Si quieres utilizar este modelo de forma adecuada, te recomiendo profundizar en estos conceptos: distribuci√≥n normal, correlaci√≥n y m√≠nimos cuadrados ordinarios (para los amantes de las matem√°ticas).\n\n‚Ä¢ Finalmente, si quieres implementar este modelo, es tan f√°cil como usar una librer√≠a de python, lo dif√≠cil es entender la teor√≠a.",
        "limitations_title": "Limitaciones",
        "limitations_text": "Existen otras relaciones en el mundo real que no siguen una l√≠nea recta, por ejemplo:"
    }
} 