{
    "app": {
        "title": "ML Educational Tools",
        "welcome": "Welcome to ML Educational Tools! üéì",
        "description": "This application provides interactive visualizations to understand machine learning concepts. Use the sidebar menu to navigate through different sections and explore various ML tools.",
        "available_sections": "Available sections:",
        "navigation": "Navigation",
        "language": "Language"
    },
    "perceptron": {
        "title": "Perceptron Visualization",
        "description": "Modify the weights and bias values to see how the decision boundary changes.",
        "weight1": "Weight w1",
        "weight2": "Weight w2",
        "bias": "Bias (b)",
        "class1": "Class 1 (y=1)",
        "class_neg1": "Class -1 (y=-1)",
        "decision_boundary": "Decision boundary",
        "graph_title": "Perceptron Classification and Decision Boundary",
        "equations_title": "Mathematical Equations",
        "perceptron_eq_title": "Perceptron Decision Rule:",
        "perceptron_eq_desc": "The perceptron classifies a point (x‚ÇÅ, x‚ÇÇ) based on this equation:",
        "line_eq_title": "Standard Line Equation:",
        "line_eq_desc": "Remember that any line can be written in the form y = mx + b, where:",
        "line_eq_params": "‚Ä¢ m is the slope of the line\n‚Ä¢ b is the y-intercept (where the line crosses the y-axis)",
        "comparison_title": "Relationship with Perceptron:",
        "comparison_text": "The perceptron's decision boundary is a line! Let's compare both equations:\n\n‚Ä¢ Standard form: x‚ÇÇ = mx‚ÇÅ + b\n‚Ä¢ Our boundary: x‚ÇÇ = -($w_1$/$w_2$)x‚ÇÅ - (b/$w_2$)\n\nTherefore:\n‚Ä¢ The slope (m) is -w‚ÇÅ/w‚ÇÇ\n‚Ä¢ The y-intercept (b) is -b/w‚ÇÇ",
        "boundary_eq_title": "Decision Boundary Equation:",
        "boundary_eq_desc": "The decision boundary is where the perceptron's output equals zero. Solving for x‚ÇÇ:",
        "explanation_title": "Understanding the Parameters:",
        "explanation_text": "‚Ä¢ w‚ÇÅ, w‚ÇÇ: Weights that determine the slope of the decision boundary\n‚Ä¢ b: Bias term, determines where the line intersects the x‚ÇÇ axis (vertical shift)\n‚Ä¢ The decision boundary is the line that separates the two classes\n‚Ä¢ Points above the line are classified as one class, points below as the other\n‚Ä¢ When w‚ÇÇ = 0, the boundary becomes a vertical line at x‚ÇÅ = -b/w‚ÇÅ",
        "line_section_title": "Remember the Basic Line",
        "line_section_desc": "Let's explore the basic line equation y = mx + b. Use the sliders below to modify the slope (m) and y-intercept (b) and see how they affect the line:",
        "line_slope": "Slope (m)",
        "line_intercept": "Y-intercept (b)",
        "line_plot_title": "Line Equation: y = mx + b",
        "exercise_title": "Practice Exercise",
        "exercise_desc": "Try to classify these points by adjusting the weights and bias. The goal is to find a line that separates the blue points from the red points.",
        "exercise_plot_title": "Practice Classification",
        "exercise_success": "Congratulations! You've successfully classified all points!",
        "exercise_continue": "Keep trying! Adjust the weights and bias to find a line that separates the classes.",
        "limitations_title": "Perceptron Limitations",
        "limitations_desc": "The perceptron can only learn linearly separable patterns. Here's an example of a non-linearly separable dataset that a perceptron cannot classify correctly:",
        "limitations_plot_title": "Non-Linearly Separable Data",
        "limitations_text": "In this example, we have two classes of points that form a circular pattern. No straight line (the perceptron's decision boundary) can separate these points correctly. This is one of the main limitations of the perceptron model.",
        "division_by_zero": "When w‚ÇÇ = 0, the decision boundary becomes a vertical line at x‚ÇÅ = -b/w‚ÇÅ. The line equation cannot be written in slope-intercept form in this case."
    },
    "linear_regression": {
        "title": "Linear Regression Visualization",
        "description": "Linear regression is one of the most fundamental machine learning algorithms. It tries to find the best line that fits through a set of points by minimizing the distance between the points and the line.\n\nIn this visualization, you can see how changing the line's parameters affects how well it fits the data points. The goal is to find the line that best represents the relationship between x and y.",
        "equations_title": "Mathematical Equations",
        "line_eq_title": "Line Equation:",
        "line_eq_desc": "The linear regression line is defined by the equation:",
        "line_eq_params": "‚Ä¢ m is the slope (how steep the line is)\n\n‚Ä¢ b is the y-intercept (where the line crosses the y-axis)\n\n‚Ä¢ For any input x, we predict y using this equation",
        "error_eq_title": "Error Measurement:",
        "error_eq_desc": "We measure how well the line fits using Mean Squared Error (MSE):",
        "error_eq_params": "‚Ä¢ n is the number of points\n\n‚Ä¢ y·µ¢ is the actual y value for point i\n\n‚Ä¢ ≈∑·µ¢ is the predicted y value for point i\n\n‚Ä¢ The smaller the MSE, the better the fit",
        "interactive_title": "Interactive Visualization",
        "interactive_desc": "Use the sliders to adjust the line parameters and see how they affect the fit:",
        "slope": "Slope (m)",
        "intercept": "Y-intercept (b)",
        "mse": "Mean Squared Error:",
        "best_fit": "Best Fit Line",
        "data_points": "Data Points",
        "error_lines": "Error Lines",
        "show_errors": "Show error lines",
        "plot_title": "Linear Regression Line and Data Points",
        "explanation_title": "Understanding Linear Regression",
        "explanation_text": "‚Ä¢ The blue dots represent our data points\n\n‚Ä¢ The red line is our prediction line (y = mx + b)\n\n‚Ä¢ The gray lines (optional) show the errors between predictions and actual values\n\n‚Ä¢ A good fit minimizes these errors\n\n‚Ä¢ The MSE value tells us how good our fit is - lower is better",
        "exercise_title": "Practice Exercise",
        "exercise_desc": "Try to find the line that best fits these points by adjusting the slope and y-intercept. Watch how the Mean Squared Error changes as you adjust the line.",
        "exercise_plot_title": "Find the Best Fit Line",
        "exercise_hint": "Hint: Try to minimize the Mean Squared Error (MSE) value"
    },
    "books": {
        "title": "Support the Project",
        "description": "If you find this educational platform helpful, you can support its development by purchasing one of my technical books:",
        "neural_networks": {
            "title": "Trapped in Neural Networks",
            "description": "A book where I share my experience working in the world of artificial intelligence. I talk a bit about technology, but above all, I want to tell a story that guides new students who want to enter this world.",
            "price": "$5.99"
        },
        "competitive_programming": {
            "title": "A Very Complex World",
            "description": "A popular science book about competitive programming. I'll teach you the fundamentals to reason like the world's best programmers.",
            "price": "$6.99"
        },
        "thank_you": "Thank you for your support!",
        "note": "Note: These books are available in Spanish."
    }
} 