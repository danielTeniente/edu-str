{
    "app": {
        "title": "Ferramentas Educativas de ML",
        "welcome": "Bem-vindo √†s Ferramentas Educativas de ML! üéì",
        "description": "Esta aplica√ß√£o fornece visualiza√ß√µes interativas para compreender conceitos de machine learning. Utilize o menu lateral para navegar pelas diferentes sec√ß√µes e explorar v√°rias ferramentas de ML.",
        "available_sections": "Sec√ß√µes dispon√≠veis:",
        "navigation": "Navega√ß√£o",
        "language": "Idioma"
    },
    "perceptron": {
        "title": "Visualiza√ß√£o do Perceptron",
        "description": "Modifique os valores dos pesos e do desvio para ver como a fronteira de decis√£o muda.",
        "weight1": "Peso w1",
        "weight2": "Peso w2",
        "bias": "Desvio (b)",
        "class1": "Classe 1 (y=1)",
        "class_neg1": "Classe -1 (y=-1)",
        "decision_boundary": "Fronteira de decis√£o",
        "graph_title": "Classifica√ß√£o do Perceptron e Fronteira de Decis√£o",
        "equations_title": "Equa√ß√µes Matem√°ticas",
        "perceptron_eq_title": "Regra de Decis√£o do Perceptron:",
        "perceptron_eq_desc": "O perceptron classifica um ponto (x‚ÇÅ, x‚ÇÇ) com base nesta equa√ß√£o:",
        "line_eq_title": "Equa√ß√£o Padr√£o da Reta:",
        "line_eq_desc": "Lembre-se que qualquer reta pode ser escrita na forma y = mx + b, onde:",
        "line_eq_params": "‚Ä¢ m √© o declive da reta\n\n‚Ä¢ b √© a ordenada na origem (onde a reta interseta o eixo y)",
        "comparison_title": "Rela√ß√£o com o Perceptron:",
        "comparison_text": "A fronteira de decis√£o do nosso perceptron √© uma reta! Vamos comparar ambas as equa√ß√µes:\n\n‚Ä¢ Forma padr√£o: x‚ÇÇ = mx‚ÇÅ + b\n\n‚Ä¢ Nossa fronteira: x‚ÇÇ = -($w_1$/$w_2$)x‚ÇÅ - (b/$w_2$)\n\nPortanto:\n\n‚Ä¢ O declive (m) √© -w‚ÇÅ/w‚ÇÇ\n\n‚Ä¢ A ordenada na origem (b) √© -b/w‚ÇÇ",
        "boundary_eq_title": "Equa√ß√£o da Fronteira de Decis√£o:",
        "boundary_eq_desc": "A fronteira de decis√£o √© onde a sa√≠da do perceptron √© igual a zero. Resolvendo para x‚ÇÇ:",
        "explanation_title": "Compreens√£o dos Par√¢metros:",
        "explanation_text": "‚Ä¢ w‚ÇÅ, w‚ÇÇ: Pesos que determinam o declive da fronteira de decis√£o\n\n‚Ä¢ b: Termo de desvio, determina onde a linha interseta o eixo x‚ÇÇ (deslocamento vertical)\n\n‚Ä¢ A fronteira de decis√£o √© a linha que separa as duas classes\n\n‚Ä¢ Os pontos acima da linha s√£o classificados como uma classe, os pontos abaixo como outra\n\n‚Ä¢ Quando w‚ÇÇ = 0, a fronteira torna-se uma linha vertical em x‚ÇÅ = -b/w‚ÇÅ",
        "line_section_title": "Lembre-se da Reta B√°sica",
        "line_section_desc": "Vamos explorar a equa√ß√£o b√°sica da reta y = mx + b. Use os deslizadores abaixo para modificar o declive (m) e a ordenada na origem (b) e ver como afetam a reta:",
        "line_slope": "Declive (m)",
        "line_intercept": "Ordenada na origem (b)",
        "line_plot_title": "Equa√ß√£o da Reta: y = mx + b",
        "exercise_title": "Exerc√≠cio Pr√°tico",
        "exercise_desc": "Tente classificar estes pontos ajustando os pesos e o desvio. O objetivo √© encontrar uma linha que separe os pontos azuis dos vermelhos.",
        "exercise_plot_title": "Classifica√ß√£o Pr√°tica",
        "exercise_success": "Parab√©ns! Voc√™ classificou corretamente todos os pontos!",
        "exercise_continue": "Continue tentando! Ajuste os pesos e o desvio para encontrar uma linha que separe as classes.",
        "limitations_title": "Limita√ß√µes do Perceptron",
        "limitations_desc": "O perceptron s√≥ pode aprender padr√µes linearmente separ√°veis. Aqui est√° um exemplo de um conjunto de dados n√£o linearmente separ√°vel que um perceptron n√£o pode classificar corretamente:",
        "limitations_plot_title": "Dados N√£o Linearmente Separ√°veis",
        "limitations_text": "Neste exemplo, temos duas classes de pontos que formam um padr√£o circular. Nenhuma linha reta (a fronteira de decis√£o do perceptron) pode separar estes pontos corretamente. Esta √© uma das principais limita√ß√µes do modelo perceptron.",
        "division_by_zero": "Quando w‚ÇÇ = 0, a fronteira de decis√£o torna-se uma linha vertical em x‚ÇÅ = -b/w‚ÇÅ. A equa√ß√£o da linha n√£o pode ser escrita na forma declive-ordenada na origem neste caso."
    },
    "linear_regression": {
        "title": "Visualiza√ß√£o de Regress√£o Linear",
        "description": "A regress√£o linear √© um dos algoritmos de machine learning mais fundamentais. Tenta encontrar a melhor linha que se ajuste a um conjunto de pontos minimizando a dist√¢ncia entre os pontos e a linha.\n\nNesta visualiza√ß√£o, pode ver como a altera√ß√£o dos par√¢metros da linha afeta o qu√£o bem ela se ajusta aos pontos de dados. O objetivo √© encontrar a linha que melhor representa a rela√ß√£o entre x e y.",
        "equations_title": "Equa√ß√µes Matem√°ticas",
        "line_eq_title": "Equa√ß√£o da Linha:",
        "line_eq_desc": "A linha de regress√£o linear √© definida pela equa√ß√£o:",
        "line_eq_params": "‚Ä¢ m √© o declive (qu√£o √≠ngreme √© a linha)\n\n‚Ä¢ b √© a ordenada na origem (onde a linha interseta o eixo y)\n\n‚Ä¢ Para qualquer entrada x, prevemos y usando esta equa√ß√£o",
        "error_eq_title": "Medi√ß√£o do Erro:",
        "error_eq_desc": "Medimos qu√£o bem a linha se ajusta usando o Erro Quadr√°tico M√©dio (MSE):",
        "error_eq_params": "‚Ä¢ n √© o n√∫mero de pontos\n\n‚Ä¢ y·µ¢ √© o valor real de y para o ponto i\n\n‚Ä¢ ≈∑·µ¢ √© o valor previsto de y para o ponto i\n\n‚Ä¢ Quanto menor o MSE, melhor √© o ajuste",
        "interactive_title": "Visualiza√ß√£o Interativa",
        "interactive_desc": "Use os deslizadores para ajustar os par√¢metros da linha e ver como afetam o ajuste:",
        "slope": "Declive (m)",
        "intercept": "Ordenada na origem (b)",
        "mse": "Erro Quadr√°tico M√©dio:",
        "best_fit": "Linha de Melhor Ajuste",
        "data_points": "Pontos de Dados",
        "error_lines": "Linhas de Erro",
        "show_errors": "Mostrar linhas de erro",
        "plot_title": "Linha de Regress√£o Linear e Pontos de Dados",
        "explanation_title": "Compreendendo a Regress√£o Linear",
        "explanation_text": "‚Ä¢ Os pontos azuis representam os nossos dados\n\n‚Ä¢ A linha vermelha √© a nossa linha de previs√£o (y = mx + b)\n\n‚Ä¢ As linhas cinzentas (opcionais) mostram os erros entre as previs√µes e os valores reais\n\n‚Ä¢ Um bom ajuste minimiza estes erros\n\n‚Ä¢ O valor MSE diz-nos qu√£o bom √© o nosso ajuste - menor √© melhor",
        "exercise_title": "Exerc√≠cio Pr√°tico",
        "exercise_desc": "Tente encontrar a linha que melhor se ajuste a estes pontos ajustando o declive e a ordenada na origem. Observe como o Erro Quadr√°tico M√©dio muda enquanto ajusta a linha.",
        "exercise_plot_title": "Encontre a Linha de Melhor Ajuste",
        "exercise_hint": "Dica: Tente minimizar o valor do Erro Quadr√°tico M√©dio (MSE)"
    }
} 