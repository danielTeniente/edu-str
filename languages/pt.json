{
    "app": {
        "title": "Machine Learning Gratuito",
        "welcome": "Bem-vindo! üéì",
        "description": "Esta aplica√ß√£o fornece visualiza√ß√µes interativas para compreender conceitos de machine learning. Use o menu lateral para navegar pelas se√ß√µes.",
        "available_sections": "Se√ß√µes dispon√≠veis:",
        "navigation": "Navega√ß√£o",
        "language": "Idioma"
    },
    "perceptron": {
        "title": "O Perceptron",
        "description": "O perceptron √© um conceito chave, pois as redes neurais modernas usam este elemento como bloco de constru√ß√£o.\n\n√â uma neur√¥nio capaz de realizar classifica√ß√£o bin√°ria baseada em regress√£o linear e uma fun√ß√£o de ativa√ß√£o.",
        "info_linear_regression": "√â importante que voc√™ j√° conhe√ßa a regress√£o linear, voc√™ pode v√™-la neste mesmo projeto.",
        "equations_title": "Equa√ß√£o do Perceptron",
        "perceptron_eq_desc_p1": "O perceptron classifica um ponto (x‚ÇÅ, x‚ÇÇ) baseado nesta equa√ß√£o:",
        "perceptron_eq_desc_p2": "Vamos entender tudo em um segundo, mas primeiro vamos revisar esta equa√ß√£o:",
        "perceptron_eq_desc_p3": "Esta equa√ß√£o representa a fronteira de decis√£o. Ou seja, divide os dados em dois conjuntos. E se movemos algumas vari√°veis, podemos obter a equa√ß√£o da reta:",
        "perceptron_eq_desc_p4": "E lembre-se da equa√ß√£o da reta.",
        "perceptron_eq_desc_p5": "* A inclina√ß√£o **m** √© **-w‚ÇÅ/w‚ÇÇ**\n\n* O intercepto y **b** √© **-b/w‚ÇÇ**",
        "perceptron_ex": "Voc√™ pode brincar com os valores do perceptron para ver como a classifica√ß√£o muda",
        "activation_title": "Fun√ß√£o de Ativa√ß√£o",
        "activation_text": "Agora podemos continuar com a fun√ß√£o de ativa√ß√£o **f(z)**. Esta fun√ß√£o determina a qual classe cada ponto pertence.\n\nVamos ver sua defini√ß√£o mais simples:",
        "activation_text_p2": "Se o valor de **z** √© maior ou igual a zero, a fun√ß√£o retorna 1. Se o valor de **z** √© menor que zero, a fun√ß√£o retorna -1. Vamos lembrar a equa√ß√£o do perceptron:",
        "activation_text_p3": "E voc√™ j√° podia ver isso no exemplo anterior. Tudo que est√° acima da fronteira de decis√£o √© de uma classe, e tudo que est√° abaixo √© da outra.",
        "exercise_title": "Exerc√≠cios",
        "exercise1_title": "Exerc√≠cio 1",
        "exercise_desc": "Tente classificar estes pontos ajustando os pesos e o bias. O objetivo √© encontrar uma reta que separe os pontos azuis dos vermelhos.",
        "weight1": "Peso w1",
        "weight2": "Peso w2",
        "bias": "Bias (b)",
        "class1": "Classe 1 (y=1)",
        "class_neg1": "Classe -1 (y=-1)",
        "decision_boundary": "Fronteira de decis√£o",
        "graph_title": "Classifica√ß√£o do Perceptron e Fronteira de Decis√£o",
        "exercise_plot_title": "Classifica√ß√£o Pr√°tica",
        "exercise_success": "Parab√©ns! Voc√™ classificou corretamente todos os pontos.",
        "exercise_continue": "√Äs vezes nem todos os pontos podem ser separados, mas a ideia √© classificar corretamente o m√°ximo poss√≠vel.",
        "correct_class1": "Pontos corretamente\n\nclassificados (y=1)",
        "correct_class_neg1": "Pontos corretamente\n\nclassificados (y=-1)",
        "misclassified": "Pontos mal classificados",
        "exercise2_title": "Exerc√≠cio 2",
        "exercise2_desc": "Agora vamos modelar uma fun√ß√£o l√≥gica. Tente modelar estas fun√ß√µes:",
        "exercise2_or": "OR: quando qualquer uma das entradas √© 1, a sa√≠da √© 1",
        "exercise2_and": "AND: quando todas as entradas s√£o 1, a sa√≠da √© 1",
        "exercise2_nand": "NAND: quando todas as entradas s√£o 1, a sa√≠da √© -1",
        "exercise2_nor": "NOR: quando todas as entradas s√£o -1, a sa√≠da √© 1",
        "exercise2_xor": "XOR: quando as entradas s√£o diferentes, a sa√≠da √© 1",
        "exercise2_nor_warning": "Cuidado! O perceptron n√£o pode modelar a fun√ß√£o NOR, pois n√£o √© linearmente separ√°vel.",
        "exercise2_result": "Resultado: voc√™ est√° modelando uma fun√ß√£o:",
        "limitations_title": "Limita√ß√µes do Perceptron",
        "limitations_desc": "O perceptron s√≥ pode aprender padr√µes Lineares, n√£o pode aprender algo como isso:",
        "limitations_plot_title": "Dados N√£o Linearmente Separ√°veis",
        "limitations_text": "Neste exemplo, temos duas classes de pontos que formam um padr√£o circular. Nenhuma reta pode separar estes pontos corretamente. Esta √© a grande limita√ß√£o do perceptron que o manteve no limbo da hist√≥ria... at√© a chegada do perceptron multicamada e o backpropagation.",
        "division_by_zero": "Quando w‚ÇÇ = 0, a fronteira de decis√£o se torna uma linha vertical em x‚ÇÅ = -b/w‚ÇÅ. A equa√ß√£o da linha n√£o pode ser escrita na forma inclina√ß√£o-intercepto neste caso."
    },
    "line_basic": {
        "title": "Lembre-se da reta b√°sica",
        "description_p1": "Lembre-se que em um plano cartesiano, podemos graficar uma reta seguindo a seguinte equa√ß√£o:",
        "description_p2": "A vari√°vel **y** √© representada no eixo vertical, enquanto a vari√°vel **x** est√° no eixo horizontal. A inclina√ß√£o **m** determina a inclina√ß√£o da reta, enquanto **b** √© o ponto onde a reta corta o eixo **y**.",
        "exercise_desc": "Voc√™ pode brincar com os deslizadores para ver como a inclina√ß√£o **m** e o intercepto **b** afetam a reta",
        "slope": "Inclina√ß√£o (m)",
        "intercept": "Intercepto Y (b)",
        "plot_title": "Equa√ß√£o da Reta: y = mx + b"
    },
    "linear_regression": {
        "title": "Regress√£o Linear",
        "description_p1": "A regress√£o linear √© um algoritmo f√°cil de entender. Consideramos que a rela√ß√£o entre duas vari√°veis pode ser vista como uma linha reta.",
        "ex_title": "Exemplo de um cen√°rio real",
        "ex_desc_p1": "Imagine que queremos prever a altura de uma pessoa (jovem) em fun√ß√£o da sua idade. Podemos usar regress√£o linear para encontrar uma reta que se ajuste aos dados.",
        "ex_desc_p2": "Neste caso, a vari√°vel independente **x** √© a idade e a vari√°vel dependente **y** √© a altura.",
        "ex_interactive_desc": "Voc√™ pode brincar com os deslizadores para encontrar uma reta que possa modelar os dados.",
        "ex_plot_title": "Exemplo de Regress√£o Linear usando a altura de uma pessoa",
        "ex_plot_x_label": "Idade (anos)",
        "ex_plot_y_label": "Altura (cm)",
        "ex_rmse": "Raiz do Erro Quadr√°tico M√©dio (RMSE):",
        "ex_hint": "Dica: Tente minimizar o valor do Erro (RMSE)",
        "error_eq_title": "Como medimos o erro?",
        "error_eq_desc_p1": "Para saber se nosso modelo √© bom, medimos a dist√¢ncia entre os valores previstos e os valores reais.",
        "error_eq_desc_p2": "E isso representa o Erro Quadr√°tico M√©dio (MSE):",
        "error_eq_params": "‚Ä¢ Onde **n** √© o n√∫mero de pontos\n\n‚Ä¢ **y·µ¢** √© o valor real para o ponto i\n\n‚Ä¢ **≈∑·µ¢** √© o valor previsto para o ponto i\n\n‚Ä¢ E quanto menor o MSE, melhor o ajuste.",
        "error_eq_desc_p3": "Note que medimos a diferen√ßa entre o valor real **y·µ¢** e o valor previsto **≈∑·µ¢** para cada ponto **i**.",
        "error_eq_desc_p4": "Elevar a diferen√ßa ao quadrado tem duas consequ√™ncias:",
        "error_eq_desc_p5": "1. Erros grandes s√£o mais importantes que erros pequenos\n\n2. A diferen√ßa √© sempre positiva, ent√£o n√£o importa se o modelo prev√™ mais ou menos que o valor real, o erro ser√° positivo.",
        "error_eq_desc_p6": "Este valor pode ser aplicada a raiz quadrada para obter o erro nas mesmas unidades que os valores reais.",
        "slope": "Inclina√ß√£o (m)",
        "intercept": "Intercepto Y (b)",
        "best_fit": "Linha de Melhor Ajuste",
        "data_points": "Pontos de Dados",
        "error_lines": "Linhas de Erro",
        "show_errors": "Mostrar linhas de erro",
        "plot_title": "Linha de Regress√£o Linear e Pontos de Dados",
        "explanation_title": "Entendendo a Regress√£o Linear",
        "explanation_text": "‚Ä¢ Assumimos que existe uma rela√ß√£o linear entre duas vari√°veis.\n\n‚Ä¢ A maneira mais f√°cil de perceber uma rela√ß√£o linear √© graficar os valores em um plano cartesiano.\n\n‚Ä¢ Nenhum modelo √© perfeito, sempre existir√° algum erro porque o mundo real n√£o tem linhas retas.\n\n‚Ä¢ Se voc√™ quiser usar este modelo adequadamente, recomendo aprofundar estes conceitos: distribui√ß√£o normal, correla√ß√£o e m√≠nimos quadrados ordin√°rios (para os amantes da matem√°tica).\n\n‚Ä¢ Finalmente, se voc√™ quiser implementar este modelo, √© t√£o f√°cil quanto usar uma biblioteca Python, o dif√≠cil √© entender a teoria.",
        "limitations_title": "Limita√ß√µes",
        "limitations_text": "Existem outras rela√ß√µes no mundo real que n√£o seguem uma linha reta, por exemplo:"
    }
} 